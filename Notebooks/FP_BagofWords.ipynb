{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Model in Pandas\n",
    "\n",
    "A bag of words is a matrix representation of a document. It consists of several columns which are unique words. And every row is a new document. The cell values of every column indicate whether the word is present in the document or not. A dataframe representation is shown below. \n",
    "\n",
    "![Image](./data/bagofwords.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column (except doc_id) is a word. Each row is a new document. The first column is the name of the document. The first row is telling us that doc_id 1987_1 does not have the word abalone, abbeel or zhou. Hence each value is 0. If the word is contained in the document then that corresponding value in the column is 1.     \n",
    "\n",
    "We have to build this bag of words model with 5 documents.  The documents are named as doc1.txt, doc2.txt, doc3.txt, doc4.txt and doc5.txt.  \n",
    "\n",
    "**There should be 5 rows in the dataframe. The columns should be unique words in all documents. The columns should have words with length greater than 4. The words should not have any punctuation marks with it.**\n",
    "\n",
    "### From the DataFrame find the following information:\n",
    "1. Find out all the common words across the five documents.\n",
    "2. Find out all the uncommon words across the five documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "f1 = open('doc1.txt','r')\n",
    "f2 = open('doc2.txt','r')\n",
    "f3 = open('doc3.txt','r')\n",
    "f4 = open('doc4.txt','r')\n",
    "f5 = open('doc5.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tutorial', 'competition', 'little', 'deeper', 'sentiment', 'analysis', \"Google's\", 'Word2Vec', 'deep-learning', 'inspired', 'method', 'focuses', 'meaning', 'words', 'Word2Vec', 'attempts', 'understand', 'meaning', 'semantic', 'relationships', 'among', 'words', 'works', 'similar', 'approaches', 'recurrent', 'neural', 'neural', 'computationally', 'efficient', 'tutorial', 'focuses', 'Word2Vec', 'sentiment', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "file1 = f1.read()\n",
    "strip_list = list(map(lambda x: x.strip(\" ,.;:'\\\"-\"),file1.split()))\n",
    "list_words1 = list(filter(lambda x: len(x) > 4,strip_list))\n",
    "print(list_words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sentiment', 'analysis', 'challenging', 'subject', 'machine', 'learning', 'People', 'express', 'their', 'emotions', 'language', 'often', 'obscured', 'sarcasm', 'ambiguity', 'plays', 'words', 'which', 'could', 'misleading', 'humans', 'computers', \"There's\", 'another', 'Kaggle', 'competition', 'movie', 'review', 'sentiment', 'analysis', 'tutorial', 'explore', 'Word2Vec', 'applied', 'similar', 'problem']\n"
     ]
    }
   ],
   "source": [
    "file2 = f2.read()\n",
    "strip_list = list(map(lambda x: x.strip(\" ,.;:'\\\"-\"),file2.split()))\n",
    "list_words2 = list(filter(lambda x: len(x) > 4,strip_list))\n",
    "print(list_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learning', 'years', 'making', 'front', 'Times', 'These', 'machine', 'learning', 'techniques', 'inspired', 'architecture', 'human', 'brain', 'possible', 'recent', 'advances', 'computing', 'power', 'making', 'waves', 'breakthrough', 'results', 'image', 'recognition', 'speech', 'processing', 'natural', 'language', 'tasks', 'Recently', 'learning', 'approaches', 'several', 'Kaggle', 'competitions', 'including', 'discovery', 'image', 'recognition']\n"
     ]
    }
   ],
   "source": [
    "file3 = f3.read()\n",
    "strip_list = list(map(lambda x: x.strip(\" ,.;:'\\\"-\"),file3.split()))\n",
    "list_words3 = list(filter(lambda x: len(x) > 4,strip_list))\n",
    "print(list_words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Since', 'learning', 'rapidly', 'evolving', 'field', 'large', 'amounts', 'published', 'exists', 'academic', 'papers', 'tutorial', 'exploratory', 'prescriptive', 'experiment', 'several', 'using', 'Word2Vec', 'rather', 'giving', 'recipe', 'using', 'output', 'achieve', 'these', 'goals', 'sentiment', 'analysis', 'which', '100,000', 'multi-paragraph', 'movie', 'reviews', 'positive', 'negative']\n"
     ]
    }
   ],
   "source": [
    "file4= f4.read()\n",
    "strip_list = list(map(lambda x: x.strip(\" ,.;:'\\\"-\"),file4.split()))\n",
    "list_words4 = list(filter(lambda x: len(x) > 4,strip_list))\n",
    "print(list_words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Word2Vec', 'labels', 'order', 'create', 'meaningful', 'representations', 'useful', 'since', 'world', 'unlabeled', 'network', 'given', 'enough', 'training', 'billions', 'words', 'produces', 'vectors', 'intriguing', 'characteristics', 'Words', 'similar', 'meanings', 'appear', 'clusters', 'clusters', 'spaced', 'relationships', 'analogies', 'reproduced', 'using', 'vector']\n"
     ]
    }
   ],
   "source": [
    "file5 = f5.read()\n",
    "strip_list = list(map(lambda x: x.strip(\" ,.;:'\\\"-)(\"),file5.split()))\n",
    "list_words5 = list(filter(lambda x: len(x) > 4,strip_list))\n",
    "print(list_words5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
